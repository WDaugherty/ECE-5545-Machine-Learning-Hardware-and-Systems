{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML-HW-SYS/a3-WDaugherty/blob/main/2_auot_conv1d_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# 1D Convolution on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOEQo1pd1ddO"
      },
      "source": [
        "## 1. Set-up "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9xe2GRFj1ddO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b04627-55d2-4410-87aa-8441ac497ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CA1bjoZe1ddP"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username    \n",
        "# with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "#     handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "d_GTOcdm1ddQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7382fe5a-7906-492e-8401-249f568ce3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/ece5545’: File exists\n",
            "/content/gdrive/MyDrive/ece5545\n",
            "fatal: destination path 'a3-WDaugherty' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/ece5545/a3-WDaugherty\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 544 bytes | 11.00 KiB/s, done.\n",
            "From https://github.com/ML-HW-SYS/a3-WDaugherty\n",
            "   1a024fc..4d2ce17  main       -> origin/main\n",
            "Updating 1a024fc..4d2ce17\n",
            "Fast-forward\n",
            " src/ops.py | 78 \u001b[32m+++++++++++++++++++++++++++++++\u001b[m\u001b[31m-------------------------------\u001b[m\n",
            " 1 file changed, 39 insertions(+), 39 deletions(-)\n",
            "/content/gdrive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = 'WDaugherty'\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AOFOUrP81ddQ"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0VDBYN2Z1ddS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f844f47b-df44-4a3c-ddd8-2d7e7b1dbfc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_auto_conv1d_cpu.ipynb  4_gemm_gpu.ipynb\t  space-time-dwsp.ipynb\n",
            "1_conv1d_cpu.ipynb\t 5-conv2d_dw_gpu.ipynb\t  space-time-GEMM.ipynb\n",
            "2-conv1d_gpu.ipynb\t leaderboard_id.txt\t  src\n",
            "2_conv1d_gpu.ipynb\t README.md\t\t  tests\n",
            "3-conv1d_fpga.ipynb\t space-time-1D_CPU.ipynb\n",
            "4-gemm_gpu.ipynb\t space-time-1D_GPU.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ircHNs-j2DYX"
      },
      "source": [
        "## 2. Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WJpFlXLd1_K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d373a9a-5359-4c04-8744-bd3e4e3888f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Collecting tlcpack-nightly-cu102\n",
            "  Downloading https://github.com/tlc-pack/tlcpack/releases/download/v0.12.dev/tlcpack_nightly_cu102-0.13.dev47%2Bg608d35717-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (5.9.4)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (6.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (2.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.10.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (22.2.0)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.22.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Installing collected packages: tlcpack-nightly-cu102\n",
            "Successfully installed tlcpack-nightly-cu102-0.13.dev47+g608d35717\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVzL-yHx1ddS"
      },
      "source": [
        "## 3. Implement `make_conv1d_gpu_scheduler_func` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 1D convolution and use TVM to optimize it.\n",
        "Let $x \\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^n$, then \n",
        "$$\n",
        "\\operatorname{conv1d}(x, y)_i = \\sum_{j=-\\infty}^{\\infty} x[j]y[i-j], \\forall i \\in \\{0, 1, \\dots, m + n - 1\\}\n",
        "$$\n",
        "\n",
        "Please use zero padding and unit stride. Please see the numpy convolution function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html).\n",
        "\n",
        "The `make_conv1d_gpu_scheduler_func` takes $m$ and $n$, which are the size of the two 1D input array. \n",
        "You should return both the TVM scheduler and the TVM opterator for \n",
        "1. Input $x$\n",
        "2. Input $y$\n",
        "3. Output $out$\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$. \n",
        "Please see the following cells for usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zY2kYOFl1ddT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "a21aed8e-1797-4c06-c520-048714a29e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[autoreload of src.ops failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
            "    module = reload(module)\n",
            "  File \"/usr/lib/python3.9/imp.py\", line 314, in reload\n",
            "    return importlib.reload(module)\n",
            "  File \"/usr/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
            "  File \"/content/gdrive/MyDrive/ece5545/a3-WDaugherty/src/ops.py\", line 212, in <module>\n",
            "    def make_conv1d_gpu_scheduler(M, N):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tvm/autotvm/task/task.py\", line 442, in _decorate\n",
            "    _register_customized_task(task_name, f)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tvm/autotvm/task/task.py\", line 376, in _register_customized_task\n",
            "    return _do_reg(func)\n",
            "ValueError: Customized func is already registered in autoTVM task make_conv1d_gpu_scheduler\n",
            "]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-9f451401feb2>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautotvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"make_conv1d_gpu_scheduler\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'llvm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Set the search space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tvm/autotvm/task/task.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(task_name, args, target, target_host)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0msch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"code_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tvm/autotvm/task/task.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcustomized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcustomized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/ece5545/a3-WDaugherty/src/ops.py\u001b[0m in \u001b[0;36mmake_conv1d_gpu_scheduler\u001b[0;34m(M, N)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_knob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unroll\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0;31m# Split and bind axes for B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mouter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"blockIdx.x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: apply() missing 1 required positional argument: 'axis'"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import numpy as np\n",
        "import sys\n",
        "import logging\n",
        "from tvm import te\n",
        "from tvm import autotvm\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_conv1d_gpu_scheduler\n",
        "\n",
        "M = 16384\n",
        "N = 32\n",
        "dtype = 'float32'\n",
        "task = autotvm.task.create(\"make_conv1d_gpu_scheduler\", args=(M, N), target='llvm')\n",
        "\n",
        "# Set the search space\n",
        "n_trial = 1000\n",
        "measure_option = autotvm.measure_option(\n",
        "    builder=autotvm.LocalBuilder(),\n",
        "    runner=autotvm.LocalRunner(number=20, repeat=3, min_repeat_ms=100, timeout=4)\n",
        ")\n",
        "\n",
        "tuner = autotvm.tuner.RandomTuner(task)\n",
        "tuner.tune(n_trial=n_trial,\n",
        "           measure_option=measure_option,\n",
        "           callbacks=[autotvm.callback.log_to_file(\"conv1d_gpu.log\")])\n",
        "\n",
        "# Load the best configuration found by AutoTVM\n",
        "dispatch_context = autotvm.apply_history_best(\"conv1d_gpu.log\")\n",
        "best_config = dispatch_context.query(task.target, task.workload)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "a_np = np.random.rand(M).astype(dtype)\n",
        "w_np = np.random.rand(N).astype(dtype)\n",
        "b_np = np.convolve(a_np, w_np)\n",
        "\n",
        "# Build the function using the best configuration\n",
        "with tvm.target.Target('llvm'):\n",
        "    with autotvm.apply_history_best(\"conv1d_gpu.log\"):\n",
        "        s, [A, W, B] = make_conv1d_gpu_scheduler(M, N)\n",
        "        func = tvm.build(s, [A, W, B], \"llvm\")\n",
        "\n",
        "\n",
        "\n",
        "dev = tvm.cpu()\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M+N-1), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat=1)\n",
        "\n",
        "print(\"Answer:\", b_np)\n",
        "print(\"Output:\", b)\n",
        "print(f\"1D conv TVM runtime: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUT5WMw41ddU"
      },
      "outputs": [],
      "source": [
        "print(tvm.lower(s, [A, W, B], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_6kV5BU1ddU",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_1dconv_gpu.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}