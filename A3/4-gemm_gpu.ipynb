{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eGZIh3o1xch"
   },
   "source": [
    "# GEMM on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IcE4c-V5Psg"
   },
   "source": [
    "## 1. Set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMbgGWP75Psg"
   },
   "outputs": [],
   "source": [
    "# Mount google drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REpyYw1o5Psi"
   },
   "outputs": [],
   "source": [
    "# Make sure your token is stored in a txt file at the location below.\n",
    "# This way there is no risk that you will push it to your repo\n",
    "# Never share your token with anyone, it is basically your github password!\n",
    "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
    "    token = f.readline().strip()\n",
    "# Use another file to store your github username    \n",
    "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
    "    handle = f.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmVrYXr05Psi"
   },
   "outputs": [],
   "source": [
    "# Clone your github repo\n",
    "YOUR_TOKEN = token\n",
    "YOUR_HANDLE = handle\n",
    "BRANCH = \"main\"\n",
    "\n",
    "%mkdir /content/gdrive/MyDrive/ece5545\n",
    "%cd /content/gdrive/MyDrive/ece5545\n",
    "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
    "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
    "!git checkout {BRANCH}\n",
    "!git pull\n",
    "%cd /content/gdrive/MyDrive/ece5545\n",
    "\n",
    "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ll4LScr_5Psi"
   },
   "outputs": [],
   "source": [
    "# This extension reloads all imports before running each cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdiSdTlu5Psj"
   },
   "outputs": [],
   "source": [
    "!ls {PROJECT_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJDlW3_V5uX8"
   },
   "source": [
    "## 2. Install TVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkqX6TEG5tz7"
   },
   "outputs": [],
   "source": [
    "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16GZ_We05Psj"
   },
   "source": [
    "## 3. Implement `make_conv1d_gpu_scheduler_func` function in `src.ops`\n",
    "\n",
    "In that function, you are required to implemented 1D convolution and use TVM to optimize it.\n",
    "Let $x \\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^n$, then \n",
    "$$\n",
    "\\operatorname{conv1d}(x, y)_i = \\sum_{j=-\\infty}^{\\infty} x[j]y[i-j], \\forall i \\in \\{0, 1, \\dots, m + n - 1\\}\n",
    "$$\n",
    "\n",
    "Please use zero padding and unit stride. Please see the numpy convolution function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html).\n",
    "\n",
    "The `make_conv1d_gpu_scheduler_func` takes $m$ and $n$, which are the size of the two 1D input array. \n",
    "You should return both the TVM scheduler and the TVM opterator for \n",
    "1. Input $x$\n",
    "2. Input $y$\n",
    "3. Output $out$\n",
    "\n",
    "The scheduler should be able to used to build a function with signature $func(x, y, out)$. \n",
    "Please see the following cells for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nIPEBHF5Psj"
   },
   "outputs": [],
   "source": [
    "import tvm\n",
    "import numpy as np\n",
    "import sys\n",
    "# Adding assignment 3 to the system path\n",
    "# Make sure this matches your git directory\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "from src.ops import make_gemm_gpu_scheduler\n",
    "\n",
    "M = 1024\n",
    "N = 512\n",
    "K = 2048\n",
    "dtype = 'float32'\n",
    "a_np = np.random.rand(M, K).astype(dtype)\n",
    "w_np = np.random.rand(K, N).astype(dtype)\n",
    "b_np = np.matmul(a_np, w_np)\n",
    "\n",
    "s, A, W, B = make_gemm_gpu_scheduler(M, K, N) \n",
    "func = tvm.build(s, [A, W, B], \"cuda\")\n",
    "\n",
    "dev = tvm.cuda(0)\n",
    "a = tvm.nd.array(a_np, dev)\n",
    "w = tvm.nd.array(w_np, dev)\n",
    "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
    "func(a, w, b)\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
    "\n",
    "\n",
    "print(\"Answer:\", b_np)\n",
    "print(\"Output:\", b)\n",
    "print(f\"1DConv TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjnf_oPi5Psk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tvm.lower(s, [A, W, B], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQiasz7n5Psk",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd {PROJECT_ROOT}\n",
    "!python -m pytest tests/test_gemm_gpu.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4-gemm_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
